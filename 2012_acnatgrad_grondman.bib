@ARTICLE{2012_acnatgrad_grondman,
author={I. Grondman and L. Busoniu and G. A. D. Lopes and R. Babuska},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
title={A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients},
year={2012},
volume={42},
number={6},
pages={1291-1307},
keywords={function approximation;gradient methods;learning (artificial intelligence);actor-critic reinforcement learning;natural policy gradients;standard policy gradients;RL;policy-gradient-based actor-critic algorithms;optimal policies;low-variance gradient estimation;real-life applications;Approximation methods;Equations;Approximation algorithms;Standards;Optimization;Convergence;Actor-critic;natural gradient;policy gradient;reinforcement learning (RL)},
doi={10.1109/TSMCC.2012.2218595},
ISSN={1094-6977},
month={Nov},}
