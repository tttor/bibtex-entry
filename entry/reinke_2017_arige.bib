@InProceedings{reinke_2017_arige,
author="Reinke, Chris
and Uchibe, Eiji
and Doya, Kenji",
editor="Liu, Derong
and Xie, Shengli
and Li, Yuanqing
and Zhao, Dongbin
and El-Alfy, El-Sayed M.",
title="Average Reward Optimization with Multiple Discounting Reinforcement Learners",
booktitle="Neural Information Processing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="789--800",
abstract="Maximization of average reward is a major goal in reinforcement learning. Existing model-free, value-based algorithms such as R-Learning use average adjusted values. We propose a different framework, the Average Reward Independent Gamma Ensemble (AR-IGE). It is based on an ensemble of discounting Q-learning modules with a different discount factor for each module. Existing algorithms only learn the optimal policy and its average reward. In contrast, the AR-IGE learns different policies and their resulting average rewards. We prove the optimality of the AR-IGE in episodic and deterministic problems where rewards are given at several goal states. Furthermore, we show that the AR-IGE outperforms existing algorithms in such problems, especially in situations where policies have to be changed due to changes in the task. The AR-IGE represents a new way to optimize average reward that could lead to further improvements in the field.",
isbn="978-3-319-70087-8"
}
