@InProceedings{thomas_2015_hcpi,
  title =    {High Confidence Policy Improvement},
  author =   {Philip Thomas and Georgios Theocharous and Mohammad Ghavamzadeh},
  booktitle =    {Proceedings of the 32nd International Conference on Machine Learning},
  pages =    {2380--2388},
  year =     {2015},
  editor =   {Francis Bach and David Blei},
  volume =   {37},
  series =   {Proceedings of Machine Learning Research},
  address =      {Lille, France},
  month =    {07--09 Jul},
  publisher =    {PMLR},
  pdf =      {http://proceedings.mlr.press/v37/thomas15.pdf},
  url =      {http://proceedings.mlr.press/v37/thomas15.html},
  abstract =     {We present a batch reinforcement learning (RL) algorithm that provides probabilistic guarantees about the quality of each policy that it proposes, and which has no hyper-parameter that requires expert tuning. Specifically, the user may select any performance lower-bound and confidence level and our algorithm will ensure that the probability that it returns a policy with performance below the lower bound is at most the specified confidence level. We then propose an incremental algorithm that executes our policy improvement algorithm repeatedly to generate multiple policy improvements. We show the viability of our approach with a simple 4 x 4 gridworld and the standard mountain car problem, as well as with a digital marketing application that uses real world data.}
}
