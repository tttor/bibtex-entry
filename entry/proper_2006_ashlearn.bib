@InProceedings{proper_2006_ashlearn,
author="Proper, Scott
and Tadepalli, Prasad",
editor="F{\"u}rnkranz, Johannes
and Scheffer, Tobias
and Spiliopoulou, Myra",
title="Scaling Model-Based Average-Reward Reinforcement Learning for Product Delivery",
booktitle="Machine Learning: ECML 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="735--742",
abstract="Reinforcement learning in real-world domains suffers from three curses of dimensionality: explosions in state and action spaces, and high stochasticity. We present approaches that mitigate each of these curses. To handle the state-space explosion, we introduce ``tabular linear functions'' that generalize tile-coding and linear value functions. Action space complexity is reduced by replacing complete joint action space search with a form of hill climbing. To deal with high stochasticity, we introduce a new algorithm called ASH-learning, which is an afterstate version of H-Learning. Our extensions make it practical to apply reinforcement learning to a domain of product delivery -- an optimization problem that combines inventory control and vehicle routing.",
isbn="978-3-540-46056-5"
}
